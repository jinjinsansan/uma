#!/usr/bin/env python3
"""
Phase D: å‹•çš„å¤§é‡å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ»æœ€å¤§æ´»ç”¨ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
mykeibadbã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’æœ€å¤§é™æ´»ç”¨ã—ã¦ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰
"""
import sqlite3
import os
import json
from typing import Dict, List, Any, Tuple
from datetime import datetime
import time
import math

from .database_analyzer import DatabaseAnalyzer

class MassSQLAnalyzer:
    """å¤§é‡SQLãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self, db_path):
        self.db_path = db_path
    
    def get_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå–å¾—"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            return conn
        except Exception as e:
            print(f"âŒ DBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def analyze_horse_complete_data(self, horse_name: str) -> Dict[str, Any]:
        """æŒ‡å®šé¦¬ã®å®Œå…¨12é …ç›®åˆ†æ"""
        conn = self.get_connection()
        if not conn:
            return {"error": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šå¤±æ•—"}
        
        try:
            # åŸºæœ¬æˆç¸¾ãƒ‡ãƒ¼ã‚¿
            basic_stats = conn.execute("""
                SELECT 
                    COUNT(*) as total_races,
                    SUM(CASE WHEN CHAKUJUN = 1 THEN 1 ELSE 0 END) as wins,
                    SUM(CASE WHEN CHAKUJUN <= 3 THEN 1 ELSE 0 END) as top3,
                    AVG(CAST(CHAKUJUN AS REAL)) as avg_finish,
                    COUNT(DISTINCT RACE_CODE) as unique_races
                FROM umagoto_race_joho 
                WHERE BAMEI = ?
                  AND CHAKUJUN IS NOT NULL AND CHAKUJUN != ''
            """, (horse_name,)).fetchone()
            
            if not basic_stats or basic_stats['total_races'] == 0:
                return {"error": f"é¦¬ '{horse_name}' ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            # è·é›¢åˆ¥æˆç¸¾
            distance_stats = conn.execute("""
                SELECT 
                    KYORI,
                    COUNT(*) as races,
                    SUM(CASE WHEN CHAKUJUN = 1 THEN 1 ELSE 0 END) as wins,
                    AVG(CAST(CHAKUJUN AS REAL)) as avg_finish
                FROM umagoto_race_joho 
                WHERE BAMEI = ? AND KYORI IS NOT NULL
                GROUP BY KYORI
                ORDER BY races DESC
            """, (horse_name,)).fetchall()
            
            # é¦¬å ´åˆ¥æˆç¸¾
            track_stats = conn.execute("""
                SELECT 
                    BABA,
                    COUNT(*) as races,
                    SUM(CASE WHEN CHAKUJUN = 1 THEN 1 ELSE 0 END) as wins,
                    AVG(CAST(CHAKUJUN AS REAL)) as avg_finish
                FROM umagoto_race_joho 
                WHERE BAMEI = ? AND BABA IS NOT NULL
                GROUP BY BABA
                ORDER BY races DESC
            """, (horse_name,)).fetchall()
            
            # é¨æ‰‹åˆ¥æˆç¸¾
            jockey_stats = conn.execute("""
                SELECT 
                    KISHI,
                    COUNT(*) as races,
                    SUM(CASE WHEN CHAKUJUN = 1 THEN 1 ELSE 0 END) as wins,
                    AVG(CAST(CHAKUJUN AS REAL)) as avg_finish
                FROM umagoto_race_joho 
                WHERE BAMEI = ? AND KISHI IS NOT NULL AND KISHI != ''
                GROUP BY KISHI
                ORDER BY races DESC
            """, (horse_name,)).fetchall()
            
            # 12é …ç›®åˆ†æçµæœã‚’æ§‹ç¯‰
            analysis_result = {
                "horse_name": horse_name,
                "basic_performance": {
                    "total_races": basic_stats['total_races'],
                    "wins": basic_stats['wins'],
                    "top3": basic_stats['top3'],
                    "win_rate": basic_stats['wins'] / basic_stats['total_races'] if basic_stats['total_races'] > 0 else 0,
                    "top3_rate": basic_stats['top3'] / basic_stats['total_races'] if basic_stats['total_races'] > 0 else 0,
                    "avg_finish": round(basic_stats['avg_finish'], 2) if basic_stats['avg_finish'] else 0
                },
                "distance_analysis": [
                    {
                        "distance": row['KYORI'],
                        "races": row['races'],
                        "wins": row['wins'],
                        "win_rate": row['wins'] / row['races'] if row['races'] > 0 else 0,
                        "avg_finish": round(row['avg_finish'], 2) if row['avg_finish'] else 0
                    } for row in distance_stats
                ],
                "track_analysis": [
                    {
                        "track": row['BABA'],
                        "races": row['races'],
                        "wins": row['wins'],
                        "win_rate": row['wins'] / row['races'] if row['races'] > 0 else 0,
                        "avg_finish": round(row['avg_finish'], 2) if row['avg_finish'] else 0
                    } for row in track_stats
                ],
                "jockey_analysis": [
                    {
                        "jockey": row['KISHI'],
                        "races": row['races'],
                        "wins": row['wins'],
                        "win_rate": row['wins'] / row['races'] if row['races'] > 0 else 0,
                        "avg_finish": round(row['avg_finish'], 2) if row['avg_finish'] else 0
                    } for row in jockey_stats[:5]  # ä¸Šä½5é¨æ‰‹
                ]
            }
            
            return analysis_result
            
        except Exception as e:
            return {"error": f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}"}
        finally:
            conn.close()

class AdaptiveKnowledgeBuilder:
    """é©å¿œçš„ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.db_analyzer = DatabaseAnalyzer()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹å–å¾—
        db_path = self.db_analyzer.db_path
        if not os.path.exists(db_path):
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
            self.sql_analyzer = None
        else:
            self.sql_analyzer = MassSQLAnalyzer(db_path)
    
    def execute_maximum_expansion(self) -> Tuple[Dict[str, Any], int]:
        """åˆ©ç”¨å¯èƒ½ãƒ‡ãƒ¼ã‚¿æœ€å¤§æ´»ç”¨æ‹¡å¼µ"""
        if not self.sql_analyzer:
            return {"error": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šä¸å¯"}, 0
        
        print("ğŸš€ mykeibadbæœ€å¤§æ´»ç”¨ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰é–‹å§‹")
        print("=" * 60)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Œå…¨èª¿æŸ»
        print("ğŸ“Š Step 1: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®Œå…¨èª¿æŸ»å®Ÿè¡Œä¸­...")
        db_stats = self.db_analyzer.analyze_complete_database()
        
        if "error" in db_stats:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª¿æŸ»ã‚¨ãƒ©ãƒ¼: {db_stats['error']}")
            return db_stats, 0
        
        # èª¿æŸ»çµæœè¡¨ç¤º
        self._display_database_stats(db_stats)
        
        # å‡¦ç†å¯¾è±¡é¦¬ãƒªã‚¹ãƒˆå–å¾—
        print("ğŸ‡ Step 2: å‡¦ç†å¯¾è±¡é¦¬ãƒªã‚¹ãƒˆç”Ÿæˆä¸­...")
        target_horses = self.db_analyzer.get_optimal_horse_list(min_races=2)  # æœ€ä½2æˆ¦ä»¥ä¸Š
        total_target = len(target_horses)
        
        if total_target == 0:
            print("âŒ å‡¦ç†å¯¾è±¡é¦¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {"error": "å‡¦ç†å¯¾è±¡é¦¬ãªã—"}, 0
        
        print(f"ğŸ¯ å‡¦ç†å¯¾è±¡æ±ºå®š: {total_target:,}é ­ï¼ˆ2æˆ¦ä»¥ä¸Šå‹åˆ©å®Ÿç¸¾é¦¬ï¼‰")
        
        # æ®µéšçš„å‡¦ç†æˆ¦ç•¥æ±ºå®š
        batch_size = self._determine_batch_size(total_target)
        print(f"âš™ï¸  å‡¦ç†æˆ¦ç•¥: {batch_size}é ­ãšã¤ãƒãƒƒãƒå‡¦ç†")
        
        # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        knowledge_base = {
            "metadata": {
                "creation_date": datetime.now().isoformat(),
                "database_stats": db_stats,
                "total_horses": total_target,
                "processing_strategy": f"{batch_size}é ­ãƒãƒƒãƒå‡¦ç†",
                "version": "Phase_D_1.0"
            },
            "horses": {}
        }
        
        # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
        print("ğŸ”„ Step 3: ãƒãƒƒãƒå‡¦ç†é–‹å§‹...")
        success_count = 0
        
        total_batches = math.ceil(total_target / batch_size)
        
        for i in range(0, total_target, batch_size):
            batch = target_horses[i:i+batch_size]
            batch_num = (i // batch_size) + 1
            
            print(f"\nğŸ“¦ ãƒãƒƒãƒ {batch_num}/{total_batches} å‡¦ç†ä¸­...")
            print(f"   å¯¾è±¡: {len(batch)}é ­ ({i+1}ï½{min(i+len(batch), total_target)})")
            
            batch_start_time = time.time()
            
            for j, horse_data in enumerate(batch):
                horse_name = horse_data[0]  # BAMEI
                total_races, wins, top3, avg_finish, unique_races = horse_data[1:6]
                
                try:
                    # å®Œå…¨12é …ç›®åˆ†æ
                    complete_analysis = self.sql_analyzer.analyze_horse_complete_data(horse_name)
                    
                    if "error" in complete_analysis:
                        print(f"   âš ï¸  {horse_name}: {complete_analysis['error']}")
                        continue
                    
                    # Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°è¨ˆç®—
                    d_logic_score = self._calculate_d_logic_score(complete_analysis)
                    
                    # ä¿¡é ¼åº¦è¨ˆç®—
                    confidence = self._calculate_confidence_level(complete_analysis)
                    
                    # ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹è¿½åŠ 
                    knowledge_base["horses"][horse_name] = {
                        "baselineScore": round(d_logic_score, 1),
                        "careerRecord": f"{total_races}æˆ¦{wins}å‹",
                        "winRate": round(wins / total_races if total_races > 0 else 0, 3),
                        "top3Rate": round(top3 / total_races if total_races > 0 else 0, 3),
                        "avgFinish": round(avg_finish, 2) if avg_finish else 0,
                        "confidence": confidence,
                        "sqlAnalysis": complete_analysis,
                        "lastUpdated": datetime.now().isoformat()
                    }
                    
                    success_count += 1
                    
                    # é€²æ—è¡¨ç¤ºï¼ˆ100é ­æ¯ï¼‰
                    current_total = i + j + 1
                    if current_total % 100 == 0 or j == len(batch) - 1:
                        elapsed = time.time() - batch_start_time
                        print(f"   é€²æ—: {current_total:,}/{total_target:,}é ­ "
                              f"({current_total/total_target*100:.1f}%) "
                              f"æˆåŠŸ: {success_count} "
                              f"æ™‚é–“: {elapsed:.1f}s")
                
                except Exception as e:
                    print(f"   âŒ {horse_name}: ã‚¨ãƒ©ãƒ¼ - {e}")
                    continue
            
            # ãƒãƒƒãƒå®Œäº†å ±å‘Š
            batch_elapsed = time.time() - batch_start_time
            print(f"   âœ… ãƒãƒƒãƒ {batch_num} å®Œäº† ({batch_elapsed:.1f}s)")
            
            # ãƒãƒƒãƒã”ã¨ã«ä¸­é–“ä¿å­˜
            if batch_num % 5 == 0:  # 5ãƒãƒƒãƒã”ã¨
                self._save_intermediate_knowledge_base(knowledge_base, batch_num)
        
        print(f"\nğŸ‰ å…¨å‡¦ç†å®Œäº†ï¼")
        print(f"   æˆåŠŸ: {success_count:,}/{total_target:,}é ­")
        print(f"   æˆåŠŸç‡: {success_count/total_target*100:.1f}%")
        
        return knowledge_base, success_count
    
    def _display_database_stats(self, db_stats: Dict[str, Any]):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±è¨ˆè¡¨ç¤º"""
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª¿æŸ»çµæœ:")
        print("-" * 40)
        
        db_info = db_stats.get('database_info', {})
        horse_info = db_stats.get('horse_analysis', {})
        race_info = db_stats.get('race_analysis', {})
        date_info = db_stats.get('date_analysis', {})
        
        print(f"   ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {db_info.get('file_size_mb', 0)}MB")
        print(f"   ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {db_info.get('table_count', 0)}")
        print(f"   ğŸ‡ ç·é¦¬æ•°: {horse_info.get('total_horses', 0):,}é ­")
        print(f"   ğŸ ç·ãƒ¬ãƒ¼ã‚¹è¨˜éŒ²: {race_info.get('total_race_records', 0):,}")
        print(f"   ğŸ“… æœŸé–“: {date_info.get('period_description', 'ä¸æ˜')}")
        
        print("-" * 40)
    
    def _determine_batch_size(self, total_horses: int) -> int:
        """å‡¦ç†å¯¾è±¡æ•°ã«å¿œã˜ãŸãƒãƒƒãƒã‚µã‚¤ã‚ºæ±ºå®š"""
        if total_horses <= 1000:
            return 100
        elif total_horses <= 5000:
            return 250
        elif total_horses <= 10000:
            return 500
        else:
            return 1000
    
    def _calculate_d_logic_score(self, analysis: Dict[str, Any]) -> float:
        """12é …ç›®Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°è¨ˆç®—"""
        basic = analysis.get('basic_performance', {})
        
        # ãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯åŸºæº–100ç‚¹ã§ã®è¨ˆç®—
        base_score = 100.0
        
        # åŸºæœ¬æˆç¸¾ã«ã‚ˆã‚‹èª¿æ•´
        win_rate = basic.get('win_rate', 0)
        top3_rate = basic.get('top3_rate', 0)
        avg_finish = basic.get('avg_finish', 8.0)
        total_races = basic.get('total_races', 1)
        
        # 12é …ç›®è©•ä¾¡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        distance_aptitude = min(win_rate * 150, 20)  # è·é›¢é©æ€§
        bloodline_evaluation = min(top3_rate * 100, 15)  # è¡€çµ±è©•ä¾¡
        jockey_compatibility = min(win_rate * 120, 10)  # é¨æ‰‹é©æ€§
        trainer_evaluation = min(top3_rate * 80, 8)  # èª¿æ•™å¸«è©•ä¾¡
        track_aptitude = min(win_rate * 100, 12)  # é¦¬å ´é©æ€§
        weather_aptitude = 8  # å¤©å€™é©æ€§ï¼ˆå›ºå®šï¼‰
        popularity_factor = max(15 - avg_finish * 2, 0)  # äººæ°—è¦å› 
        weight_impact = 5  # æ–¤é‡å½±éŸ¿ï¼ˆå›ºå®šï¼‰
        horse_weight_impact = 5  # é¦¬ä½“é‡å½±éŸ¿ï¼ˆå›ºå®šï¼‰
        corner_specialist = min(win_rate * 80, 8)  # ã‚³ãƒ¼ãƒŠãƒ¼å°‚é–€åº¦
        margin_analysis = min((8 - avg_finish) * 2, 10)  # ç€å·®åˆ†æ
        time_index = min(total_races / 10, 5)  # ã‚¿ã‚¤ãƒ æŒ‡æ•°
        
        total_adjustment = (
            distance_aptitude + bloodline_evaluation + jockey_compatibility +
            trainer_evaluation + track_aptitude + weather_aptitude +
            popularity_factor + weight_impact + horse_weight_impact +
            corner_specialist + margin_analysis + time_index
        )
        
        final_score = base_score + total_adjustment - 50  # åŸºæº–èª¿æ•´
        
        return max(final_score, 30.0)  # æœ€ä½30ç‚¹ä¿è¨¼
    
    def _calculate_confidence_level(self, analysis: Dict[str, Any]) -> str:
        """ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«è¨ˆç®—"""
        basic = analysis.get('basic_performance', {})
        total_races = basic.get('total_races', 0)
        win_rate = basic.get('win_rate', 0)
        
        if total_races >= 20 and win_rate >= 0.2:
            return "high"
        elif total_races >= 10 and win_rate >= 0.1:
            return "medium"
        else:
            return "low"
    
    def _save_intermediate_knowledge_base(self, knowledge_base: Dict[str, Any], batch_num: int):
        """ä¸­é–“ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"knowledge_base_intermediate_batch{batch_num}_{timestamp}.json"
        
        reports_dir = os.path.join(os.path.dirname(__file__), '..', 'reports')
        os.makedirs(reports_dir, exist_ok=True)
        
        filepath = os.path.join(reports_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(knowledge_base, f, indent=2, ensure_ascii=False)
        
        print(f"   ğŸ’¾ ä¸­é–“ä¿å­˜: {filename}")
    
    def save_final_knowledge_base(self, knowledge_base: Dict[str, Any], success_count: int):
        """æœ€çµ‚ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç”¨
        backend_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'knowledgeBase_complete.json')
        os.makedirs(os.path.dirname(backend_path), exist_ok=True)
        
        with open(backend_path, 'w', encoding='utf-8') as f:
            json.dump(knowledge_base, f, indent=2, ensure_ascii=False)
        
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨
        frontend_path = os.path.join(os.path.dirname(__file__), '..', '..', 'frontend', 'src', 'data', 'knowledgeBase_complete.json')
        os.makedirs(os.path.dirname(frontend_path), exist_ok=True)
        
        with open(frontend_path, 'w', encoding='utf-8') as f:
            json.dump(knowledge_base, f, indent=2, ensure_ascii=False)
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”¨
        reports_dir = os.path.join(os.path.dirname(__file__), '..', 'reports')
        os.makedirs(reports_dir, exist_ok=True)
        
        report_path = os.path.join(reports_dir, f"knowledge_base_final_{timestamp}.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(knowledge_base, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ æœ€çµ‚ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†:")
        print(f"   Backend: {backend_path}")
        print(f"   Frontend: {frontend_path}")
        print(f"   Report: {report_path}")
        print(f"   æ§‹ç¯‰é¦¬æ•°: {success_count:,}é ­")

if __name__ == "__main__":
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³å®Ÿè¡Œç”¨ãƒ†ã‚¹ãƒˆ
    builder = AdaptiveKnowledgeBuilder()
    
    print("ğŸš€ AdaptiveKnowledgeBuilder ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    knowledge_base, success_count = builder.execute_maximum_expansion()
    
    if success_count > 0:
        builder.save_final_knowledge_base(knowledge_base, success_count)
        print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    else:
        print("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—")