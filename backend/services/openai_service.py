import os
import logging
from typing import Dict, Any, List
from fastapi import HTTPException
from config import OPENAI_API_KEY, OPENAI_MODEL, DEBUG
from services.enhanced_knowledge_base import enhanced_knowledge_base

logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        self.api_key = OPENAI_API_KEY
        if not self.api_key or self.api_key == "dummy_key":
            logger.warning("OPENAI_API_KEY not found in environment variables")
            self.api_key = "dummy_key"  # é–‹ç™ºç”¨ãƒ€ãƒŸãƒ¼ã‚­ãƒ¼
        
        self.model = OPENAI_MODEL
    
    async def chat_completion(self, messages: List[Dict[str, str]], system_prompt: str = None) -> str:
        """OpenAI Chat Completions APIã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆå¿œç­”ã‚’ç”Ÿæˆ"""
        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
            if system_prompt:
                messages.insert(0, {"role": "system", "content": system_prompt})
            
            from openai import OpenAI
            client = OpenAI(api_key=self.api_key)
            
            response = await client.chat.completions.acreate(
                model=self.model,
                messages=messages,
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            # é–‹ç™ºç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”
            return self._get_fallback_response(messages[-1]["content"] if messages else "")
    
    def _get_fallback_response(self, user_message: str) -> str:
        """é–‹ç™ºç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿œç­”"""
        if "æŒ‡æ•°" in user_message or "Dãƒ­ã‚¸ãƒƒã‚¯" in user_message:
            return "Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°ã®è¨ˆç®—ã‚’é–‹å§‹ã—ã¾ã™ã€‚ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—ã—ã¦ã€12é …ç›®ã®å¤šè§’çš„è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚"
        elif "ãƒ¬ãƒ¼ã‚¹" in user_message:
            return "æœ¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ç¢ºèªã„ãŸã—ã¾ã™ã€‚ã©ã®ãƒ¬ãƒ¼ã‚¹ã®æŒ‡æ•°ã‚’ãŠæ±‚ã‚ã§ã—ã‚‡ã†ã‹ï¼Ÿ"
        else:
            return "ç«¶é¦¬äºˆæƒ³ã«ã¤ã„ã¦ä½•ã§ã‚‚ãŠèããã ã•ã„ã€‚æœ¬æ—¥ã®ãƒ¬ãƒ¼ã‚¹ã®æŒ‡æ•°ã‚’å‡ºã—ãŸã„å ´åˆã¯ã€Œæœ¬æ—¥ã®æ±äº¬3Rã®æŒ‡æ•°ã‚’å‡ºã—ã¦ã€ã®ã‚ˆã†ã«ãŠèããã ã•ã„ã€‚"
    
    async def generate_race_analysis(self, race_info: Dict[str, Any], d_logic_result: Dict[str, Any] = None) -> str:
        """ãƒ¬ãƒ¼ã‚¹åˆ†æã®è‡ªç„¶è¨€èªèª¬æ˜ã‚’ç”Ÿæˆ"""
        try:
            system_prompt = """ã‚ãªãŸã¯ç«¶é¦¬äºˆæƒ³ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€åˆ†ã‹ã‚Šã‚„ã™ãè‡ªç„¶ãªæ—¥æœ¬èªã§ãƒ¬ãƒ¼ã‚¹åˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

åˆ†æã®ãƒã‚¤ãƒ³ãƒˆï¼š
- ãƒ¬ãƒ¼ã‚¹ã®ç‰¹å¾´ï¼ˆè·é›¢ã€é¦¬å ´çŠ¶æ…‹ã€å‡ºèµ°é ­æ•°ãªã©ï¼‰
- æ³¨ç›®é¦¬ã®ç´¹ä»‹
- äºˆæƒ³ã®æ ¹æ‹ 
- Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°ãŒã‚ã‚‹å ´åˆã¯ã€ãã®çµæœã‚’è‡ªç„¶ã«çµ„ã¿è¾¼ã‚€

å›ç­”ã¯è¦ªã—ã¿ã‚„ã™ãã€å°‚é–€çš„ã™ããªã„è¡¨ç¾ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚"""

            user_message = f"""
ãƒ¬ãƒ¼ã‚¹æƒ…å ±ï¼š
- ç«¶é¦¬å ´: {race_info.get('keibajo_name', 'ä¸æ˜')}
- ãƒ¬ãƒ¼ã‚¹ç•ªå·: {race_info.get('race_bango', 'ä¸æ˜')}
- è·é›¢: {race_info.get('kyori', 'ä¸æ˜')}m
- å‡ºèµ°é ­æ•°: {race_info.get('shusso_tosu', 'ä¸æ˜')}é ­
- é¦¬å ´çŠ¶æ…‹: {race_info.get('track_condition', 'ä¸æ˜')}
- å¤©å€™: {race_info.get('weather', 'ä¸æ˜')}

Dãƒ­ã‚¸ãƒƒã‚¯åˆ†æçµæœ: {d_logic_result if d_logic_result else 'æœªè¨ˆç®—'}
"""

            messages = [
                {"role": "user", "content": user_message}
            ]
            
            return await self.chat_completion(messages, system_prompt)
            
        except Exception as e:
            logger.error(f"Race analysis generation error: {e}")
            return "ãƒ¬ãƒ¼ã‚¹åˆ†æã‚’ç”Ÿæˆä¸­ã§ã™ã€‚Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°ã®è¨ˆç®—çµæœã¨åˆã‚ã›ã¦è©³ç´°ãªåˆ†æã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚"
    
    async def generate_d_logic_explanation(self, d_logic_result: Dict[str, Any]) -> str:
        """Dãƒ­ã‚¸ãƒƒã‚¯çµæœã®è‡ªç„¶è¨€èªèª¬æ˜ã‚’ç”Ÿæˆï¼ˆPhase Dæœ€å¼·é¦¬ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ´»ç”¨ï¼‰"""
        try:
            # Phase D ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—
            knowledge_context = enhanced_knowledge_base.get_context_for_llm_prompt()
            
            system_prompt = f"""ã‚ãªãŸã¯ç«¶é¦¬äºˆæƒ³ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®Phase Dæœ€å¼·é¦¬ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ã¦ã€Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°ã®çµæœã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚

{knowledge_context}

èª¬æ˜ã®ãƒã‚¤ãƒ³ãƒˆï¼š
- ç·åˆæŒ‡æ•°ã®æ„å‘³ï¼ˆãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯åŸºæº–100ç‚¹ï¼‰
- ä¸Šä½é¦¬ã®ç‰¹å¾´ã¨é¡ä¼¼ã™ã‚‹ä¼èª¬é¦¬ã¨ã®æ¯”è¼ƒ
- 12é …ç›®D-Logicåˆ†æçµæœã®è©³ç´°è§£èª¬
- Phase Dåˆ†æã«ã‚ˆã‚‹ç§‘å­¦çš„æ ¹æ‹ 
- äºˆæƒ³ã®ä¿¡é ¼åº¦ã¨çš„ä¸­å¯èƒ½æ€§

959,620ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ»109,426é ­ãƒ»71å¹´é–“ã®æ—¥æœ¬ç«¶é¦¬å²ä¸Šæœ€å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å°å‡ºã•ã‚ŒãŸçµæœã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿ã—ã¦ãã ã•ã„ã€‚"""

            # Dãƒ­ã‚¸ãƒƒã‚¯çµæœã‚’è©³ç´°åˆ†æ
            horses_info = ""
            legendary_comparison = ""
            
            if 'horses' in d_logic_result:
                legendary_horses = enhanced_knowledge_base.get_legendary_horses()
                
                for i, horse in enumerate(d_logic_result['horses'][:3]):  # ä¸Šä½3é ­
                    horse_name = horse.get('horse_name', 'ä¸æ˜')
                    score = horse.get('total_score', 0)
                    grade = horse.get('grade', '')
                    analysis_source = horse.get('analysis_source', '')
                    
                    horses_info += f"\n{i+1}ä½: {horse_name} - æŒ‡æ•°{score:.1f}ç‚¹ ({grade})"
                    horses_info += f"\n    åˆ†æå…ƒ: {analysis_source}"
                    
                    # ä¼èª¬é¦¬ã¨ã®æ¯”è¼ƒ
                    if horse_name in legendary_horses:
                        legendary_data = legendary_horses[horse_name]
                        specialties = horse.get('specialties', [])
                        win_rate = horse.get('horse_stats', {}).get('win_rate', 0)
                        
                        legendary_comparison += f"\nğŸ“Š {horse_name}ã¯ä¼èª¬ã®æœ€å¼·é¦¬ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«åéŒ²æ¸ˆã¿ï¼ˆå‹ç‡{win_rate:.1f}%ï¼‰"
                        if specialties:
                            legendary_comparison += f"\n   ç‰¹å¾´: {', '.join(specialties[:2])}"

            user_message = f"""
Phase Då®Œå…¨åˆ†æçµæœï¼š
- åˆ†æè¦æ¨¡: {d_logic_result.get('sql_data_utilization', '959,620ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ»109,426é ­ãƒ»71å¹´é–“')}
- è¨ˆç®—æ–¹æ³•: {d_logic_result.get('calculation_method', 'ãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯åŸºæº–100ç‚¹ãƒ»12é …ç›®D-Logic')}
- åŸºæº–é¦¬: {d_logic_result.get('base_horse', 'ãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯')}
- åŸºæº–ã‚¹ã‚³ã‚¢: {d_logic_result.get('base_score', 100)}ç‚¹

ä¸Šä½é¦¬ã®è©³ç´°æŒ‡æ•°{horses_info}

ä¼èª¬é¦¬ã¨ã®æ¯”è¼ƒ{legendary_comparison}

ã“ã®çµæœã‚’ã€Phase Dæœ€å¼·é¦¬ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã¨ç…§ã‚‰ã—åˆã‚ã›ã¦è©³ã—ãè§£èª¬ã—ã¦ãã ã•ã„ã€‚
"""

            messages = [
                {"role": "user", "content": user_message}
            ]
            
            return await self.chat_completion(messages, system_prompt)
            
        except Exception as e:
            logger.error(f"D-logic explanation generation error: {e}")
            return "Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°ã®è¨ˆç®—ãŒå®Œäº†ã—ã¾ã—ãŸã€‚è©³ç´°ãªåˆ†æçµæœã‚’ã”ç¢ºèªãã ã•ã„ã€‚"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
openai_service = OpenAIService() 