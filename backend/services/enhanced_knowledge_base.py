#!/usr/bin/env python3
"""
Phase Dçµ±åˆ: ç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ»LLMçµ±åˆã‚·ã‚¹ãƒ†ãƒ 
959,620ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ»50é ­å®Œå…¨åˆ†æãƒ‡ãƒ¼ã‚¿ã‚’LLMã«æ³¨å…¥
"""
import json
import os
from typing import Dict, Any, Optional, List
from pathlib import Path
from datetime import datetime

class EnhancedKnowledgeBase:
    """Phase Dç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±åˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.data_dir = Path(__file__).parent.parent / "data"
        self.reports_dir = Path(__file__).parent.parent / "reports"
        
        # Phase Dç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿
        self.ultimate_knowledge = self._load_ultimate_knowledge_base()
        
        # å¾“æ¥ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹
        self.legacy_knowledge = self._load_legacy_knowledge_base()
        
        # çµ±åˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
        self.integrated_knowledge = self._integrate_knowledge_bases()
        
        print("ğŸš€ Phase Dç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±åˆå®Œäº†")
        print(f"ğŸ“Š æœ€å¼·é¦¬ãƒ‡ãƒ¼ã‚¿: {len(self.get_legendary_horses())}é ­")
        print(f"ğŸ¯ å‹åˆ©ãƒ‘ã‚¿ãƒ¼ãƒ³: {len(self.get_winning_patterns())}ç¨®é¡")
    
    def _load_ultimate_knowledge_base(self) -> Dict[str, Any]:
        """Phase Dç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿"""
        try:
            # æœ€æ–°ã®ultimate_knowledge_baseãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            pattern = "ultimate_knowledge_base_*.json"
            files = list(self.reports_dir.glob(pattern))
            
            if files:
                # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
                latest_file = max(files, key=lambda f: f.stat().st_mtime)
                print(f"âœ… ç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿: {latest_file.name}")
                
                with open(latest_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                print("âš ï¸  ç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return {}
                
        except Exception as e:
            print(f"âŒ ç©¶æ¥µãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def _load_legacy_knowledge_base(self) -> Dict[str, Any]:
        """å¾“æ¥ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿"""
        try:
            knowledge_file = self.data_dir / "knowledgeBase.json"
            if knowledge_file.exists():
                with open(knowledge_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"å¾“æ¥ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿
        return {
            "reference_horse": {
                "name": "ãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯",
                "base_score": 100,
                "description": "Dãƒ­ã‚¸ãƒƒã‚¯æŒ‡æ•°ã®åŸºæº–é¦¬"
            },
            "scoring_weights": {
                "distance_aptitude": 1.2,
                "bloodline_evaluation": 1.1,
                "jockey_compatibility": 1.0,
                "trainer_evaluation": 1.0,
                "track_aptitude": 1.1,
                "weather_aptitude": 0.9,
                "popularity_factor": 0.8,
                "weight_impact": 0.9,
                "horse_weight_impact": 0.8,
                "corner_specialist": 1.0,
                "margin_analysis": 1.1,
                "time_index": 1.2
            }
        }
    
    def _integrate_knowledge_bases(self) -> Dict[str, Any]:
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹çµ±åˆ"""
        integrated = self.legacy_knowledge.copy()
        
        if self.ultimate_knowledge:
            # Phase D ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ
            integrated.update({
                "phase_d_data": {
                    "legendary_horses": self.ultimate_knowledge.get("legendary_horses", {}),
                    "winning_patterns": self.ultimate_knowledge.get("winning_patterns", {}),
                    "prediction_accuracy": self.ultimate_knowledge.get("prediction_accuracy", {}),
                    "total_horses_analyzed": self.ultimate_knowledge.get("total_horses_analyzed", 0),
                    "database_stats": {
                        "total_records": 959620,
                        "total_horses": 109426,
                        "data_span_years": 71,
                        "analysis_timestamp": self.ultimate_knowledge.get("analysis_timestamp", "")
                    }
                },
                "enhanced_references": self._create_enhanced_references(),
                "llm_context": self._create_llm_context()
            })
        
        return integrated
    
    def _create_enhanced_references(self) -> Dict[str, Any]:
        """å¼·åŒ–å‚ç…§ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
        legendary_horses = self.ultimate_knowledge.get("legendary_horses", {})
        winning_patterns = self.ultimate_knowledge.get("winning_patterns", {})
        
        # æœ€å¼·é¦¬ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‚ç…§å€¤ã‚’æŠ½å‡º
        distance_refs = {}
        jockey_refs = {}
        bloodline_refs = {}
        
        for horse_name, horse_data in legendary_horses.items():
            d_logic = horse_data.get("d_logic_scores", {})
            stats = horse_data.get("detailed_stats", {})
            
            # é«˜å¾—ç‚¹é …ç›®ã‚’å‚ç…§ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
            if d_logic.get("1_distance_aptitude", 0) > 85:
                distance_refs[horse_name] = {
                    "score": d_logic.get("1_distance_aptitude"),
                    "win_rate": stats.get("win_rate", 0)
                }
            
            if d_logic.get("2_bloodline_evaluation", 0) >= 95:
                bloodline_refs[horse_name] = {
                    "score": d_logic.get("2_bloodline_evaluation"),
                    "total_wins": stats.get("wins", 0)
                }
        
        return {
            "legendary_distance_specialists": distance_refs,
            "legendary_bloodline_horses": bloodline_refs,
            "high_performers": winning_patterns.get("high_performers", []),
            "versatile_champions": winning_patterns.get("versatile_champions", [])
        }
    
    def _create_llm_context(self) -> Dict[str, Any]:
        """LLMç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ"""
        legendary_horses = self.ultimate_knowledge.get("legendary_horses", {})
        winning_patterns = self.ultimate_knowledge.get("winning_patterns", {})
        
        # ãƒˆãƒƒãƒ—10é¦¬ã®è¦ç´„
        top_horses = []
        high_performers = winning_patterns.get("high_performers", [])[:10]
        
        for horse_info in high_performers:
            horse_name = horse_info.get("horse", "")
            if horse_name in legendary_horses:
                horse_data = legendary_horses[horse_name]
                top_horses.append({
                    "name": horse_name,
                    "score": horse_info.get("score", 0),
                    "grade": horse_info.get("grade", ""),
                    "wins": horse_info.get("wins", 0),
                    "win_rate": horse_info.get("win_rate", 0),
                    "career_span": horse_data.get("detailed_stats", {}).get("career_span", {}).get("span", ""),
                    "specialties": self._extract_horse_specialties(horse_data)
                })
        
        return {
            "database_summary": f"959,620ãƒ¬ã‚³ãƒ¼ãƒ‰ãƒ»109,426é ­ãƒ»71å¹´é–“ã®æ—¥æœ¬ç«¶é¦¬å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
            "analysis_method": "ãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯åŸºæº–100ç‚¹ãƒ»12é …ç›®D-Logicåˆ†æ",
            "top_legendary_horses": top_horses,
            "winning_patterns_summary": {
                "high_performers_count": len(winning_patterns.get("high_performers", [])),
                "distance_specialists_count": len(winning_patterns.get("distance_specialists", [])),
                "versatile_champions_count": len(winning_patterns.get("versatile_champions", [])),
                "bloodline_excellence_count": len(winning_patterns.get("bloodline_excellence", []))
            },
            "prediction_accuracy": self.ultimate_knowledge.get("prediction_accuracy", {}),
            "last_updated": datetime.now().isoformat()
        }
    
    def _extract_horse_specialties(self, horse_data: Dict[str, Any]) -> List[str]:
        """é¦¬ã®å°‚é–€æ€§ã‚’æŠ½å‡º"""
        d_logic = horse_data.get("d_logic_scores", {})
        specialties = []
        
        if d_logic.get("1_distance_aptitude", 0) > 90:
            specialties.append("è·é›¢é©æ€§æŠœç¾¤")
        if d_logic.get("2_bloodline_evaluation", 0) >= 95:
            specialties.append("è¡€çµ±å„ªç§€")
        if d_logic.get("3_jockey_compatibility", 0) > 90:
            specialties.append("é¨æ‰‹ç›¸æ€§è‰¯å¥½")
        if d_logic.get("5_track_aptitude", 0) > 85:
            specialties.append("é¦¬å ´é©æ€§é«˜")
        if d_logic.get("11_margin_analysis", 0) > 90:
            specialties.append("å‹è² å¼·ã„")
        
        return specialties[:3]  # ä¸Šä½3ã¤ã®ç‰¹å¾´
    
    def get_legendary_horses(self) -> Dict[str, Any]:
        """ä¼èª¬ã®é¦¬ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        return self.integrated_knowledge.get("phase_d_data", {}).get("legendary_horses", {})
    
    def get_winning_patterns(self) -> Dict[str, Any]:
        """å‹åˆ©ãƒ‘ã‚¿ãƒ¼ãƒ³å–å¾—"""
        return self.integrated_knowledge.get("phase_d_data", {}).get("winning_patterns", {})
    
    def get_llm_context(self) -> Dict[str, Any]:
        """LLMç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—"""
        return self.integrated_knowledge.get("llm_context", {})
    
    def get_enhanced_references(self) -> Dict[str, Any]:
        """å¼·åŒ–å‚ç…§ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        return self.integrated_knowledge.get("enhanced_references", {})
    
    def find_similar_horse(self, target_stats: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """é¡ä¼¼é¦¬æ¤œç´¢"""
        legendary_horses = self.get_legendary_horses()
        target_win_rate = target_stats.get("win_rate", 0)
        target_races = target_stats.get("total_races", 0)
        
        best_match = None
        best_similarity = 0
        
        for horse_name, horse_data in legendary_horses.items():
            stats = horse_data.get("detailed_stats", {})
            horse_win_rate = stats.get("win_rate", 0)
            horse_races = stats.get("total_races", 0)
            
            # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆå‹ç‡ãƒ»å‡ºèµ°æ•°ã®å·®ã‹ã‚‰ï¼‰
            win_rate_diff = abs(target_win_rate - horse_win_rate)
            races_diff = abs(target_races - horse_races) / 100  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
            
            similarity = 1 / (1 + win_rate_diff + races_diff)
            
            if similarity > best_similarity:
                best_similarity = similarity
                best_match = {
                    "name": horse_name,
                    "similarity": similarity,
                    "data": horse_data,
                    "comparison": {
                        "target_win_rate": target_win_rate,
                        "horse_win_rate": horse_win_rate,
                        "target_races": target_races,
                        "horse_races": horse_races
                    }
                }
        
        return best_match if best_similarity > 0.5 else None
    
    def get_prediction_insights(self, horse_name: str) -> Dict[str, Any]:
        """äºˆæƒ³ã‚¤ãƒ³ã‚µã‚¤ãƒˆå–å¾—"""
        legendary_horses = self.get_legendary_horses()
        
        if horse_name in legendary_horses:
            horse_data = legendary_horses[horse_name]
            d_logic = horse_data.get("d_logic_scores", {})
            stats = horse_data.get("detailed_stats", {})
            
            # å¼·ã¿ãƒ»å¼±ã¿åˆ†æ
            strengths = []
            weaknesses = []
            
            for key, score in d_logic.items():
                item_name = key.split('_', 1)[1] if '_' in key else key
                
                if score > 85:
                    strengths.append(f"{item_name}: {score:.1f}")
                elif score < 50:
                    weaknesses.append(f"{item_name}: {score:.1f}")
            
            return {
                "total_score": horse_data.get("dance_in_the_dark_total_score", 0),
                "grade": horse_data.get("performance_grade", ""),
                "win_rate": stats.get("win_rate", 0),
                "total_races": stats.get("total_races", 0),
                "career_span": stats.get("career_span", {}).get("span", ""),
                "strengths": strengths[:3],
                "weaknesses": weaknesses[:2],
                "specialties": self._extract_horse_specialties(horse_data)
            }
        
        return {}
    
    def get_context_for_llm_prompt(self) -> str:
        """LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—ç”Ÿæˆ"""
        llm_context = self.get_llm_context()
        top_horses = llm_context.get("top_legendary_horses", [])[:5]
        
        context = f"""
ç«¶é¦¬äºˆæƒ³AI ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ¦‚è¦:
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {llm_context.get('database_summary', '')}
- åˆ†ææ‰‹æ³•: {llm_context.get('analysis_method', '')}

ä¼èª¬ã®æœ€å¼·é¦¬ TOP5:
"""
        
        for i, horse in enumerate(top_horses, 1):
            context += f"{i}. {horse.get('name', '')} - ã‚¹ã‚³ã‚¢{horse.get('score', 0):.1f} ({horse.get('grade', '')}) - å‹ç‡{horse.get('win_rate', 0):.1%}\n"
            if horse.get('specialties'):
                context += f"   ç‰¹å¾´: {', '.join(horse.get('specialties', []))}\n"
        
        winning_patterns = llm_context.get("winning_patterns_summary", {})
        context += f"""
å‹åˆ©ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ:
- é«˜å¾—ç‚¹é¦¬: {winning_patterns.get('high_performers_count', 0)}é ­
- è·é›¢ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆ: {winning_patterns.get('distance_specialists_count', 0)}é ­  
- ä¸‡èƒ½å‹ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³: {winning_patterns.get('versatile_champions_count', 0)}é ­
- è¡€çµ±å„ªç§€é¦¬: {winning_patterns.get('bloodline_excellence_count', 0)}é ­

ã“ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã‚’æ´»ç”¨ã—ã¦ã€ç§‘å­¦çš„æ ¹æ‹ ã«åŸºã¥ã„ãŸç«¶é¦¬äºˆæƒ³ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚
"""
        
        return context.strip()
    
    def save_integrated_knowledge_base(self) -> str:
        """çµ±åˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"integrated_knowledge_base_{timestamp}.json"
        filepath = self.data_dir / filename
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.data_dir.mkdir(exist_ok=True)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.integrated_knowledge, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"âœ… çµ±åˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä¿å­˜: {filename}")
            return str(filepath)
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return ""

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
enhanced_knowledge_base = EnhancedKnowledgeBase()

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("\nğŸ§ª Phase Dçµ±åˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ")
    
    # ä¼èª¬ã®é¦¬ç¢ºèª
    legendary_horses = enhanced_knowledge_base.get_legendary_horses()
    print(f"ğŸ“Š ä¼èª¬ã®é¦¬ãƒ‡ãƒ¼ã‚¿: {len(legendary_horses)}é ­")
    
    # LLMã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç¢ºèª
    context = enhanced_knowledge_base.get_context_for_llm_prompt()
    print(f"ğŸ¤– LLMã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(context)}æ–‡å­—")
    
    # çµ±åˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ä¿å­˜
    saved_path = enhanced_knowledge_base.save_integrated_knowledge_base()
    print(f"ğŸ’¾ ä¿å­˜ãƒ‘ã‚¹: {saved_path}")
    
    print("\nâœ… Phase Dçµ±åˆãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æº–å‚™å®Œäº†!")