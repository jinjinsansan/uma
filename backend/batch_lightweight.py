#!/usr/bin/env python3
"""
ËªΩÈáèÁâà„Éê„ÉÉ„ÉÅÂá¶ÁêÜ - Â§ß„Åç„Å™JSON„Éï„Ç°„Ç§„É´„ÇíÈÅø„Åë„Å¶Áõ¥Êé•Âá¶ÁêÜ
"""
import os
import sys
import json
import time
from datetime import datetime
from typing import Dict, List, Any

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„Éà„Çí„Éë„Çπ„Å´ËøΩÂä†
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from utils.mysql_connection_manager import get_mysql_manager

# MySQLÊé•Á∂ö„Éû„Éç„Éº„Ç∏„É£„Éº
mysql_manager = get_mysql_manager()

def lightweight_batch_process():
    """ËªΩÈáèÁâà„Éê„ÉÉ„ÉÅÂá¶ÁêÜ"""
    start_time = time.time()
    print("üöÄ ËªΩÈáèÁâà„Éê„ÉÉ„ÉÅÂá¶ÁêÜÈñãÂßã")
    print(f"üïê ÈñãÂßãÊôÇÂàª: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Êé•Á∂ö„ÉÜ„Çπ„Éà
    if not mysql_manager.test_connection():
        print("‚ùå MySQLÊé•Á∂ö„ÉÜ„Çπ„ÉàÂ§±Êïó")
        return
    print("‚úÖ MySQLÊé•Á∂ö„ÉÜ„Çπ„ÉàÊàêÂäü")
    
    # Êñ∞„Åó„ÅÑ„Éä„É¨„ÉÉ„Ç∏„Éï„Ç°„Ç§„É´„Éë„Çπ
    output_file = f"data/new_knowledge_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    # Êó¢Â≠ò„ÅÆ„Éä„É¨„ÉÉ„Ç∏„Åã„ÇâÂá¶ÁêÜÊ∏à„ÅøÈ¶¨Âêç„ÅÆ„ÅøÂèñÂæóÔºà„É°„É¢„É™ÂäπÁéáÂåñÔºâ
    existing_horses = set()
    existing_file = "data/dlogic_raw_knowledge.json"
    
    print(f"üìã Êó¢Â≠ò„Éá„Éº„Çø„ÅÆÈ¶¨Âêç„ÅÆ„ÅøË™≠„ÅøËæº„Åø‰∏≠...")
    if os.path.exists(existing_file):
        try:
            # „Éï„Ç°„Ç§„É´„ÇíË°å„Åî„Å®„Å´Ë™≠„Çì„ÅßÈ¶¨Âêç„ÅÆ„ÅøÊäΩÂá∫
            with open(existing_file, 'r', encoding='utf-8') as f:
                content = f.read()
                if '"horses"' in content:
                    # Á∞°Âçò„Å™ÊñáÂ≠óÂàóËß£Êûê„ÅßÈ¶¨Âêç„ÇíÊäΩÂá∫
                    start_idx = content.find('"horses": {')
                    if start_idx != -1:
                        horses_section = content[start_idx:start_idx + 100000]  # ÊúÄÂàù„ÅÆ100KBÁ®ãÂ∫¶
                        import re
                        horse_names = re.findall(r'"([^"]+)": \{', horses_section)
                        existing_horses = set(horse_names)
                        print(f"‚úÖ Êó¢Â≠òÈ¶¨Âêç {len(existing_horses):,}È†≠„ÇíÁâπÂÆö")
        except Exception as e:
            print(f"‚ö†Ô∏è Êó¢Â≠ò„Éá„Éº„ÇøË™≠„ÅøËæº„Åø„Ç®„É©„Éº: {e}")
    
    # „Éá„Éº„Çø„Éô„Éº„Çπ„Åã„ÇâÊú™Âá¶ÁêÜÈ¶¨„ÇíÂèñÂæó
    print("üêé Êú™Âá¶ÁêÜÈ¶¨„ÅÆÊäΩÂá∫‰∏≠...")
    try:
        horses = mysql_manager.execute_query("""
            SELECT DISTINCT BAMEI, COUNT(*) as race_count
            FROM umagoto_race_joho 
            WHERE KAISAI_NEN >= '2020'
            AND BAMEI IS NOT NULL 
            AND BAMEI != ''
            AND KAKUTEI_CHAKUJUN IS NOT NULL
            GROUP BY BAMEI
            HAVING race_count >= 3
            ORDER BY race_count DESC
            LIMIT 1000
        """)
        
        unprocessed_horses = [h for h in horses if h['BAMEI'] not in existing_horses]
        total_unprocessed = len(unprocessed_horses)
        
        print(f"üéØ ÂØæË±°È¶¨Êï∞: {len(horses):,}È†≠")
        print(f"üÜï Êú™Âá¶ÁêÜÈ¶¨Êï∞: {total_unprocessed:,}È†≠")
        
        if total_unprocessed == 0:
            print("‚úÖ ÂÖ®„Å¶„ÅÆÈ¶¨„ÅÆÂá¶ÁêÜ„ÅåÂÆå‰∫Ü„Åó„Å¶„ÅÑ„Åæ„Åô")
            return
        
        # Êñ∞„Åó„ÅÑ„Éä„É¨„ÉÉ„Ç∏„Éá„Éº„Çø„Çí‰ΩúÊàê
        new_knowledge = {
            "meta": {
                "version": "1.1",
                "created": datetime.now().isoformat(),
                "source": "lightweight_batch",
                "horses_count": 0
            },
            "horses": {}
        }
        
        processed = 0
        errors = 0
        batch_size = 50
        
        print(f"üèÅ {total_unprocessed:,}È†≠„ÅÆÂá¶ÁêÜÈñãÂßã")
        
        for i, horse_data in enumerate(unprocessed_horses):
            horse_name = horse_data['BAMEI']
            
            try:
                # ËªΩÈáè„Éá„Éº„ÇøÊäΩÂá∫
                raw_data = extract_horse_data_minimal(horse_name)
                
                if raw_data:
                    new_knowledge["horses"][horse_name] = raw_data
                    processed += 1
                    
                    # ÈÄ≤Ë°åÁä∂Ê≥ÅË°®Á§∫
                    if processed % 10 == 0:
                        elapsed = time.time() - start_time
                        speed = processed / elapsed if elapsed > 0 else 0
                        remaining = total_unprocessed - processed
                        eta = remaining / speed if speed > 0 else 0
                        
                        print(f"‚è≥ {processed:,}/{total_unprocessed:,} ÂÆå‰∫Ü "
                              f"({processed/total_unprocessed*100:.1f}%) "
                              f"ÈÄüÂ∫¶: {speed:.1f}È†≠/Áßí "
                              f"ÊÆã„ÇäÊôÇÈñì: {eta/60:.1f}ÂàÜ")
                    
                    # „Éê„ÉÉ„ÉÅ‰øùÂ≠ò
                    if processed % batch_size == 0:
                        new_knowledge["meta"]["horses_count"] = processed
                        with open(output_file, 'w', encoding='utf-8') as f:
                            json.dump(new_knowledge, f, ensure_ascii=False, indent=2)
                        print(f"üíæ ‰∏≠Èñì‰øùÂ≠ò: {processed:,}È†≠ÂÆå‰∫Ü")
                else:
                    errors += 1
                    
            except Exception as e:
                errors += 1
                if errors % 10 == 0:
                    print(f"‚ö†Ô∏è „Ç®„É©„ÉºÁ¥ØË®à: {errors}‰ª∂")
        
        # ÊúÄÁµÇ‰øùÂ≠ò
        new_knowledge["meta"]["horses_count"] = processed
        new_knowledge["meta"]["completed"] = datetime.now().isoformat()
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(new_knowledge, f, ensure_ascii=False, indent=2)
        
        elapsed = time.time() - start_time
        
        print("\n" + "="*60)
        print("üéâ ËªΩÈáèÁâà„Éê„ÉÉ„ÉÅÂá¶ÁêÜÂÆå‰∫ÜÔºÅ")
        print(f"üìä ÁµêÊûú:")
        print(f"   - Êñ∞Ë¶èËøΩÂä†: {processed:,}È†≠")
        print(f"   - „Ç®„É©„ÉºÊï∞: {errors:,}‰ª∂")
        print(f"   - ÂÆüË°åÊôÇÈñì: {elapsed/60:.1f}ÂàÜ")
        print(f"   - Âá¶ÁêÜÈÄüÂ∫¶: {processed/(elapsed/60):.1f}È†≠/ÂàÜ")
        print(f"   - Âá∫Âäõ„Éï„Ç°„Ç§„É´: {output_file}")
        print("="*60)
        
    except Exception as e:
        print(f"‚ùå Âá¶ÁêÜ„Ç®„É©„Éº: {str(e)}")

def extract_horse_data_minimal(horse_name: str) -> Dict[str, Any]:
    """ÊúÄÂ∞èÈôê„ÅÆ„Éá„Éº„ÇøÊäΩÂá∫"""
    try:
        races = mysql_manager.execute_query("""
            SELECT 
                KAKUTEI_CHAKUJUN as finish,
                TANSHO_ODDS as odds,
                TANSHO_NINKIJUN as popularity,
                KAISAI_NEN as year,
                KAISAI_GAPPI as date
            FROM umagoto_race_joho 
            WHERE BAMEI = %s
            AND KAISAI_NEN >= '2020'
            AND KAKUTEI_CHAKUJUN IS NOT NULL
            ORDER BY KAISAI_NEN DESC, KAISAI_GAPPI DESC
            LIMIT 15
        """, (horse_name,))
        
        if not races:
            return None
        
        # Âü∫Êú¨Áµ±Ë®à
        total_races = len(races)
        wins = sum(1 for race in races if race.get('finish') == 1)
        avg_odds = sum(float(race.get('odds', 0)) for race in races if race.get('odds')) / max(1, total_races)
        
        return {
            "name": horse_name,
            "total_races": total_races,
            "wins": wins,
            "win_rate": round(wins / total_races * 100, 1) if total_races > 0 else 0,
            "avg_odds": round(avg_odds, 1),
            "recent_races": races[:10],
            "processed_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"‚ùå {horse_name}„ÅÆ„Éá„Éº„ÇøÊäΩÂá∫„Ç®„É©„Éº: {e}")
        return None

if __name__ == "__main__":
    lightweight_batch_process()